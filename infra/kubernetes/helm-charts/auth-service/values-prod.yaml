replicaCount: 3

image:
  pullPolicy: IfNotPresent

resources:
  requests:
    cpu: 200m
    memory: 256Mi
  limits:
    cpu: 1000m
    memory: 1Gi

startupProbe:
  initialDelaySeconds: 5
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 12

livenessProbe:
  initialDelaySeconds: 0
  periodSeconds: 15
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  initialDelaySeconds: 0
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 12
  targetCPUUtilizationPercentage: 60
  targetMemoryUtilizationPercentage: 70
  scaleDown:
    stabilizationWindowSeconds: 300
    percentPodPolicy:
      value: 10
      periodSeconds: 60
  scaleUp:
    stabilizationWindowSeconds: 60
    percentPodPolicy:
      value: 50
      periodSeconds: 30
    podsPodPolicy:
      value: 3
      periodSeconds: 60

podDisruptionBudget:
  enabled: true
  minAvailable: 2

terminationGracePeriodSeconds: 60

updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    maxSurge: 2
    maxUnavailable: 0

priorityClassName: high-priority

affinity:
  podAntiAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
                - auth-service
        topologyKey: kubernetes.io/hostname
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                  - auth-service
          topologyKey: topology.kubernetes.io/zone

topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: topology.kubernetes.io/zone
    whenUnsatisfiable: DoNotSchedule
    labelSelector:
      matchLabels:
        app.kubernetes.io/name: auth-service
  - maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: DoNotSchedule
    labelSelector:
      matchLabels:
        app.kubernetes.io/name: auth-service

tolerations:
  - key: dedicated
    operator: Equal
    value: auth-tier
    effect: NoSchedule

nodeSelector:
  node-role: auth-tier

env:
  NODE_ENV: production
  LOG_LEVEL: warn
  LOG_FORMAT: json
  TRUST_PROXY: "1"

  JWT_ALGORITHM: RS256
  JWT_ACCESS_TOKEN_EXPIRY: 15m
  JWT_REFRESH_TOKEN_EXPIRY: 7d
  JWT_AUDIENCE: api.lomashwood.co.uk
  JWT_ISSUER: auth.lomashwood.co.uk
  JWT_CLOCK_TOLERANCE_SECONDS: "10"
  JWT_KEY_PATH: /app/keys

  REFRESH_TOKEN_ROTATION: "true"
  REFRESH_TOKEN_FAMILY_INVALIDATION: "true"
  REFRESH_TOKEN_ABSOLUTE_EXPIRY: 30d
  COOKIE_SECURE: "true"
  COOKIE_SAME_SITE: strict
  COOKIE_DOMAIN: .lomashwood.co.uk
  COOKIE_HTTP_ONLY: "true"

  MFA_TOTP_ISSUER: "Lomash Wood"
  MFA_TOTP_WINDOW: "1"
  MFA_BACKUP_CODE_COUNT: "10"
  MFA_BACKUP_CODE_LENGTH: "8"
  MFA_RATE_LIMIT_ATTEMPTS: "5"
  MFA_RATE_LIMIT_WINDOW_MS: "300000"

  BCRYPT_SALT_ROUNDS: "12"
  PASSWORD_MIN_LENGTH: "12"
  PASSWORD_MAX_LENGTH: "128"
  PASSWORD_REQUIRE_UPPERCASE: "true"
  PASSWORD_REQUIRE_LOWERCASE: "true"
  PASSWORD_REQUIRE_NUMBER: "true"
  PASSWORD_REQUIRE_SYMBOL: "true"
  PASSWORD_BREACHED_CHECK: "true"

  RATE_LIMIT_LOGIN_WINDOW_MS: "900000"
  RATE_LIMIT_LOGIN_MAX: "10"
  RATE_LIMIT_REGISTER_WINDOW_MS: "3600000"
  RATE_LIMIT_REGISTER_MAX: "5"
  RATE_LIMIT_PASSWORD_RESET_WINDOW_MS: "3600000"
  RATE_LIMIT_PASSWORD_RESET_MAX: "3"
  RATE_LIMIT_MFA_WINDOW_MS: "300000"
  RATE_LIMIT_MFA_MAX: "5"

  BRUTE_FORCE_FREE_RETRIES: "3"
  BRUTE_FORCE_MIN_WAIT_MS: "5000"
  BRUTE_FORCE_MAX_WAIT_MS: "900000"
  BRUTE_FORCE_LIFETIME_SECONDS: "86400"

  SESSION_ABSOLUTE_TIMEOUT_MS: "86400000"
  SESSION_IDLE_TIMEOUT_MS: "1800000"
  SESSION_MAX_PER_USER: "5"

  EMAIL_VERIFICATION_EXPIRY_HOURS: "24"
  PASSWORD_RESET_EXPIRY_HOURS: "1"

  CORS_ORIGIN: "https://www.lomashwood.co.uk,https://admin.lomashwood.co.uk"
  CORS_METHODS: "GET,POST,PUT,DELETE,OPTIONS"
  CORS_CREDENTIALS: "true"

  DATABASE_POOL_MIN: "5"
  DATABASE_POOL_MAX: "20"
  DATABASE_CONNECTION_TIMEOUT_MS: "10000"
  DATABASE_IDLE_TIMEOUT_MS: "30000"
  DATABASE_STATEMENT_TIMEOUT_MS: "15000"

  REDIS_KEY_PREFIX: "lomash:auth:"
  REDIS_CONNECT_TIMEOUT_MS: "5000"
  REDIS_COMMAND_TIMEOUT_MS: "500"
  REDIS_MAX_RETRIES: "3"

  NOTIFICATION_SERVICE_URL: http://notification-service.lomashwood.svc.cluster.local
  USER_SERVICE_URL: http://user-service.lomashwood.svc.cluster.local

  HEALTH_CHECK_DISK_THRESHOLD: "0.9"
  HEALTH_CHECK_MEMORY_THRESHOLD: "0.9"

networkPolicy:
  enabled: true
  ingress:
    - from:
        - podSelector:
            matchLabels:
              app.kubernetes.io/name: api-gateway
        - podSelector:
            matchLabels:
              app.kubernetes.io/name: prometheus
      ports:
        - protocol: TCP
          port: 3001
        - protocol: TCP
          port: 9090
  egress:
    - to:
        - namespaceSelector:
            matchLabels:
              kubernetes.io/metadata.name: lomashwood-data
      ports:
        - protocol: TCP
          port: 5432
        - protocol: TCP
          port: 6379
    - to:
        - podSelector:
            matchLabels:
              app.kubernetes.io/name: notification-service
        - podSelector:
            matchLabels:
              app.kubernetes.io/name: user-service
      ports:
        - protocol: TCP
          port: 80
    - ports:
        - protocol: TCP
          port: 443
    - ports:
        - protocol: UDP
          port: 53
        - protocol: TCP
          port: 53

serviceMonitor:
  enabled: true
  namespace: monitoring
  interval: 15s
  scrapeTimeout: 10s
  labels:
    release: prometheus
  relabelings:
    - sourceLabels: [__meta_kubernetes_pod_node_name]
      targetLabel: node
  metricRelabelings:
    - sourceLabels: [__name__]
      regex: go_.*
      action: drop

prometheusRule:
  enabled: true
  namespace: monitoring
  labels:
    release: prometheus
  rules:
    - alert: AuthServiceHighLoginFailureRate
      expr: |
        sum(rate(auth_login_failures_total{service="auth-service"}[5m]))
        /
        sum(rate(auth_login_attempts_total{service="auth-service"}[5m])) > 0.2
      for: 2m
      labels:
        severity: critical
        environment: production
        team: security
      annotations:
        summary: Auth Service login failure rate above 20%
        description: "Login failure rate is {{ $value | humanizePercentage }}. Possible credential stuffing or brute-force attack."
        runbook: https://runbooks.lomashwood.co.uk/auth-service/high-login-failure-rate
    - alert: AuthServiceBruteForceDetected
      expr: |
        sum(rate(auth_brute_force_blocks_total{service="auth-service"}[5m])) > 5
      for: 1m
      labels:
        severity: critical
        environment: production
        team: security
      annotations:
        summary: Auth Service brute-force blocks exceeding 5/s
        description: "Brute-force block rate is {{ $value | humanize }}/s. Immediate investigation required."
        runbook: https://runbooks.lomashwood.co.uk/auth-service/brute-force
    - alert: AuthServiceHighErrorRate
      expr: |
        sum(rate(http_requests_total{service="auth-service",status=~"5.."}[5m]))
        /
        sum(rate(http_requests_total{service="auth-service"}[5m])) > 0.01
      for: 2m
      labels:
        severity: critical
        environment: production
        team: platform
      annotations:
        summary: Auth Service 5xx error rate above 1%
        description: "Error rate is {{ $value | humanizePercentage }}."
        runbook: https://runbooks.lomashwood.co.uk/auth-service/high-error-rate
    - alert: AuthServiceHighTokenRefreshLatency
      expr: |
        histogram_quantile(0.95, sum(rate(auth_token_refresh_duration_seconds_bucket{service="auth-service"}[5m])) by (le)) > 0.2
      for: 5m
      labels:
        severity: warning
        environment: production
        team: platform
      annotations:
        summary: Auth Service token refresh p95 latency above 200ms
        description: "p95 refresh latency is {{ $value | humanizeDuration }}."
        runbook: https://runbooks.lomashwood.co.uk/auth-service/high-latency
    - alert: AuthServiceHighLoginLatency
      expr: |
        histogram_quantile(0.95, sum(rate(auth_login_duration_seconds_bucket{service="auth-service"}[5m])) by (le)) > 1
      for: 5m
      labels:
        severity: warning
        environment: production
        team: platform
      annotations:
        summary: Auth Service login p95 latency above 1s
        description: "p95 login latency is {{ $value | humanizeDuration }}. Possible bcrypt under load."
        runbook: https://runbooks.lomashwood.co.uk/auth-service/high-latency
    - alert: AuthServicePodCount
      expr: |
        kube_deployment_status_replicas_available{deployment="auth-service"} < 2
      for: 1m
      labels:
        severity: critical
        environment: production
        team: platform
      annotations:
        summary: Auth Service available pod count below 2
        description: "Only {{ $value }} pods available."
        runbook: https://runbooks.lomashwood.co.uk/auth-service/pod-count
    - alert: AuthServiceSuspiciousMFAFailures
      expr: |
        sum(rate(auth_mfa_failures_total{service="auth-service"}[10m])) > 10
      for: 5m
      labels:
        severity: warning
        environment: production
        team: security
      annotations:
        summary: Auth Service sustained MFA failures above 10/min
        description: "MFA failure rate is {{ $value | humanize }}/s. Possible MFA bypass attempt."
        runbook: https://runbooks.lomashwood.co.uk/auth-service/mfa-failures

podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/path: "/metrics"
  prometheus.io/port: "9090"
  cluster-autoscaler.kubernetes.io/safe-to-evict: "true"

podLabels:
  tier: auth
  criticality: critical

lifecycle:
  preStop:
    exec:
      command:
        - /bin/sh
        - -c
        - sleep 10