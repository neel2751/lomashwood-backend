replicaCount: 3

image:
  pullPolicy: IfNotPresent

resources:
  requests:
    cpu: 250m
    memory: 512Mi
  limits:
    cpu: 1500m
    memory: 2Gi

startupProbe:
  initialDelaySeconds: 10
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 18

livenessProbe:
  initialDelaySeconds: 0
  periodSeconds: 20
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  initialDelaySeconds: 0
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 15
  targetCPUUtilizationPercentage: 65
  targetMemoryUtilizationPercentage: 70
  scaleDown:
    stabilizationWindowSeconds: 300
    percentPodPolicy:
      value: 10
      periodSeconds: 60
  scaleUp:
    stabilizationWindowSeconds: 60
    percentPodPolicy:
      value: 50
      periodSeconds: 30
    podsPodPolicy:
      value: 3
      periodSeconds: 60

podDisruptionBudget:
  enabled: true
  minAvailable: 2

terminationGracePeriodSeconds: 120

updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    maxSurge: 2
    maxUnavailable: 0

priorityClassName: high-priority

affinity:
  podAntiAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
                - notification-service
        topologyKey: kubernetes.io/hostname
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                  - notification-service
          topologyKey: topology.kubernetes.io/zone

topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: topology.kubernetes.io/zone
    whenUnsatisfiable: DoNotSchedule
    labelSelector:
      matchLabels:
        app.kubernetes.io/name: notification-service
  - maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: DoNotSchedule
    labelSelector:
      matchLabels:
        app.kubernetes.io/name: notification-service

tolerations:
  - key: dedicated
    operator: Equal
    value: notification-tier
    effect: NoSchedule

nodeSelector:
  node-role: notification-tier

env:
  NODE_ENV: production
  LOG_LEVEL: warn
  LOG_FORMAT: json
  TRUST_PROXY: "1"

  EMAIL_QUEUE_NAME: "lomash:email"
  SMS_QUEUE_NAME: "lomash:sms"
  PUSH_QUEUE_NAME: "lomash:push"
  EMAIL_WORKER_CONCURRENCY: "5"
  SMS_WORKER_CONCURRENCY: "10"
  PUSH_WORKER_CONCURRENCY: "20"
  QUEUE_REMOVE_ON_COMPLETE_AGE: "86400"
  QUEUE_REMOVE_ON_FAIL_COUNT: "1000"
  QUEUE_DEFAULT_JOB_ATTEMPTS: "3"
  QUEUE_STALLED_INTERVAL_MS: "30000"
  QUEUE_MAX_STALLED_COUNT: "2"
  QUEUE_LOCK_DURATION_MS: "30000"

  EMAIL_PROVIDER_PRIMARY: nodemailer-smtp
  EMAIL_PROVIDER_FALLBACK: aws-ses
  EMAIL_FROM_NAME: "Lomash Wood"
  EMAIL_FROM_ADDRESS: noreply@lomashwood.co.uk
  EMAIL_REPLY_TO: hello@lomashwood.co.uk
  EMAIL_RATE_LIMIT_PER_MINUTE: "300"
  EMAIL_RETRY_MAX_ATTEMPTS: "4"
  EMAIL_RETRY_INITIAL_DELAY_MS: "5000"
  EMAIL_RETRY_MAX_DELAY_MS: "300000"
  EMAIL_RETRY_MULTIPLIER: "3"
  NODEMAILER_POOL: "true"
  NODEMAILER_MAX_CONNECTIONS: "5"
  NODEMAILER_MAX_MESSAGES: "100"
  SES_REGION: eu-west-2
  SES_MAX_SEND_RATE: "14"

  SMS_PROVIDER_PRIMARY: twilio-sms
  SMS_PROVIDER_FALLBACK: msg91-sms
  SMS_RATE_LIMIT_PER_MINUTE: "60"
  SMS_RETRY_MAX_ATTEMPTS: "3"
  SMS_RETRY_INITIAL_DELAY_MS: "3000"
  SMS_RETRY_MAX_DELAY_MS: "120000"
  SMS_RETRY_MULTIPLIER: "2"

  PUSH_PROVIDER_PRIMARY: firebase-fcm
  PUSH_PROVIDER_FALLBACK: web-push
  PUSH_RATE_LIMIT_PER_MINUTE: "1000"
  PUSH_RETRY_MAX_ATTEMPTS: "3"
  PUSH_TTL_SECONDS: "86400"
  VAPID_SUBJECT: mailto:push@lomashwood.co.uk

  TEMPLATE_CACHE_TTL_SECONDS: "3600"
  TEMPLATE_CACHE_MAX_ITEMS: "500"
  TEMPLATE_COMPILE_TIMEOUT_MS: "5000"

  CAMPAIGN_BATCH_SIZE: "1000"
  CAMPAIGN_SEND_DELAY_MS: "100"
  CAMPAIGN_MAX_RECIPIENTS: "100000"
  CAMPAIGN_SCHEDULE_CHECK_INTERVAL_MS: "60000"

  WEBHOOK_RETRY_MAX_ATTEMPTS: "5"
  WEBHOOK_TIMEOUT_MS: "10000"

  RATE_LIMIT_WINDOW_MS: "60000"
  RATE_LIMIT_MAX_REQUESTS: "100"

  DATABASE_POOL_MIN: "5"
  DATABASE_POOL_MAX: "20"
  DATABASE_CONNECTION_TIMEOUT_MS: "10000"
  DATABASE_IDLE_TIMEOUT_MS: "30000"
  DATABASE_STATEMENT_TIMEOUT_MS: "30000"

  REDIS_KEY_PREFIX: "lomash:notif:"
  REDIS_CONNECT_TIMEOUT_MS: "5000"
  REDIS_COMMAND_TIMEOUT_MS: "2000"
  REDIS_MAX_RETRIES: "3"

  ANALYTICS_SERVICE_URL: http://analytics-service.lomashwood.svc.cluster.local
  USER_SERVICE_URL: http://user-service.lomashwood.svc.cluster.local

  HEALTH_CHECK_DISK_THRESHOLD: "0.9"
  HEALTH_CHECK_MEMORY_THRESHOLD: "0.9"
  HEALTH_CHECK_QUEUE_WAIT_THRESHOLD: "1000"

networkPolicy:
  enabled: true
  ingress:
    - from:
        - podSelector:
            matchLabels:
              app.kubernetes.io/name: api-gateway
        - podSelector:
            matchLabels:
              app.kubernetes.io/name: auth-service
        - podSelector:
            matchLabels:
              app.kubernetes.io/name: order-service
        - podSelector:
            matchLabels:
              app.kubernetes.io/name: appointment-service
        - podSelector:
            matchLabels:
              app.kubernetes.io/name: prometheus
      ports:
        - protocol: TCP
          port: 3004
        - protocol: TCP
          port: 9090
  egress:
    - to:
        - namespaceSelector:
            matchLabels:
              kubernetes.io/metadata.name: lomashwood-data
      ports:
        - protocol: TCP
          port: 5432
        - protocol: TCP
          port: 6379
    - to:
        - podSelector:
            matchLabels:
              app.kubernetes.io/name: analytics-service
        - podSelector:
            matchLabels:
              app.kubernetes.io/name: user-service
      ports:
        - protocol: TCP
          port: 80
    - ports:
        - protocol: TCP
          port: 443
    - ports:
        - protocol: UDP
          port: 53
        - protocol: TCP
          port: 53

serviceMonitor:
  enabled: true
  namespace: monitoring
  interval: 15s
  scrapeTimeout: 10s
  labels:
    release: prometheus
  relabelings:
    - sourceLabels: [__meta_kubernetes_pod_node_name]
      targetLabel: node
  metricRelabelings:
    - sourceLabels: [__name__]
      regex: go_.*
      action: drop

prometheusRule:
  enabled: true
  namespace: monitoring
  labels:
    release: prometheus
  rules:
    - alert: NotificationServiceHighDeliveryFailureRate
      expr: |
        sum(rate(notification_delivery_failures_total{service="notification-service"}[5m]))
        /
        sum(rate(notification_delivery_attempts_total{service="notification-service"}[5m])) > 0.05
      for: 2m
      labels:
        severity: critical
        environment: production
        team: platform
      annotations:
        summary: Notification Service delivery failure rate above 5%
        description: "Failure rate is {{ $value | humanizePercentage }}. Provider failover may be triggered."
        runbook: https://runbooks.lomashwood.co.uk/notification-service/high-failure-rate
    - alert: NotificationServiceEmailQueueDepthCritical
      expr: |
        bullmq_queue_waiting{service="notification-service",queue="lomash:email"} > 10000
      for: 5m
      labels:
        severity: critical
        environment: production
        team: platform
      annotations:
        summary: Notification Service email queue depth above 10,000
        description: "Email queue has {{ $value | humanize }} waiting jobs. Worker capacity may be insufficient."
        runbook: https://runbooks.lomashwood.co.uk/notification-service/queue-depth
    - alert: NotificationServiceSMSQueueDepthHigh
      expr: |
        bullmq_queue_waiting{service="notification-service",queue="lomash:sms"} > 2000
      for: 5m
      labels:
        severity: warning
        environment: production
        team: platform
      annotations:
        summary: Notification Service SMS queue depth above 2,000
        description: "SMS queue has {{ $value | humanize }} waiting jobs."
        runbook: https://runbooks.lomashwood.co.uk/notification-service/queue-depth
    - alert: NotificationServiceStalledJobs
      expr: |
        sum(bullmq_queue_stalled{service="notification-service"}) > 50
      for: 5m
      labels:
        severity: warning
        environment: production
        team: platform
      annotations:
        summary: Notification Service has more than 50 stalled jobs
        description: "{{ $value | humanize }} stalled jobs detected. Workers may be unresponsive."
        runbook: https://runbooks.lomashwood.co.uk/notification-service/stalled-jobs
    - alert: NotificationServiceHighErrorRate
      expr: |
        sum(rate(http_requests_total{service="notification-service",status=~"5.."}[5m]))
        /
        sum(rate(http_requests_total{service="notification-service"}[5m])) > 0.01
      for: 2m
      labels:
        severity: critical
        environment: production
        team: platform
      annotations:
        summary: Notification Service 5xx error rate above 1%
        description: "Error rate is {{ $value | humanizePercentage }}."
        runbook: https://runbooks.lomashwood.co.uk/notification-service/high-error-rate
    - alert: NotificationServiceEmailProviderDown
      expr: |
        sum(notification_provider_healthy{service="notification-service",channel="email"}) == 0
      for: 1m
      labels:
        severity: critical
        environment: production
        team: platform
      annotations:
        summary: All email providers are unhealthy
        description: "Both primary and fallback email providers are reporting failures. Email delivery is suspended."
        runbook: https://runbooks.lomashwood.co.uk/notification-service/provider-down
    - alert: NotificationServiceSMSProviderDown
      expr: |
        sum(notification_provider_healthy{service="notification-service",channel="sms"}) == 0
      for: 1m
      labels:
        severity: critical
        environment: production
        team: platform
      annotations:
        summary: All SMS providers are unhealthy
        description: "Both primary and fallback SMS providers are reporting failures. SMS delivery is suspended."
        runbook: https://runbooks.lomashwood.co.uk/notification-service/provider-down
    - alert: NotificationServicePodCount
      expr: |
        kube_deployment_status_replicas_available{deployment="notification-service"} < 2
      for: 1m
      labels:
        severity: critical
        environment: production
        team: platform
      annotations:
        summary: Notification Service available pod count below 2
        description: "Only {{ $value }} pods available. Queue processing capacity is degraded."
        runbook: https://runbooks.lomashwood.co.uk/notification-service/pod-count
    - alert: NotificationServiceCampaignSendLatencyHigh
      expr: |
        histogram_quantile(0.95, sum(rate(notification_campaign_send_duration_seconds_bucket{service="notification-service"}[10m])) by (le)) > 30
      for: 10m
      labels:
        severity: warning
        environment: production
        team: platform
      annotations:
        summary: Notification Service campaign send p95 latency above 30s
        description: "Campaign p95 send duration is {{ $value | humanizeDuration }}. Large campaigns may be impacting throughput."
        runbook: https://runbooks.lomashwood.co.uk/notification-service/campaign-latency

podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/path: "/metrics"
  prometheus.io/port: "9090"
  cluster-autoscaler.kubernetes.io/safe-to-evict: "true"

podLabels:
  tier: notification
  criticality: high

lifecycle:
  preStop:
    exec:
      command:
        - /bin/sh
        - -c
        - sleep 15